{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9524149-1a99-4135-baef-409810c0f5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in /opt/anaconda3/lib/python3.12/site-packages (0.5.1)\n",
      "Requirement already satisfied: httpx>=0.27 in /opt/anaconda3/lib/python3.12/site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.9 in /opt/anaconda3/lib/python3.12/site-packages (from ollama) (2.11.7)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.27->ollama) (4.7.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.27->ollama) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.27->ollama) (1.0.2)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.27->ollama) (3.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic>=2.9->ollama) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic>=2.9->ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic>=2.9->ollama) (4.14.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic>=2.9->ollama) (0.4.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/lib/python3.12/site-packages (from anyio->httpx>=0.27->ollama) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: PyPDF2 in /opt/anaconda3/lib/python3.12/site-packages (3.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ollama\n",
    "%pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c8579a9-21dc-4a4b-b2c3-d9057ad67b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>company_name</th>\n",
       "      <th>industry</th>\n",
       "      <th>job_title</th>\n",
       "      <th>skills_required</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>location</th>\n",
       "      <th>salary_range_usd</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>company_size</th>\n",
       "      <th>tools_preferred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Foster and Sons</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>NumPy, Reinforcement Learning, PyTorch, Scikit...</td>\n",
       "      <td>Mid</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Tracybury, AR</td>\n",
       "      <td>92860-109598</td>\n",
       "      <td>2025-08-20</td>\n",
       "      <td>Large</td>\n",
       "      <td>KDB+, LangChain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Boyd, Myers and Ramirez</td>\n",
       "      <td>Tech</td>\n",
       "      <td>Computer Vision Engineer</td>\n",
       "      <td>Scikit-learn, CUDA, SQL, Pandas</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Lake Scott, CU</td>\n",
       "      <td>78523-144875</td>\n",
       "      <td>2024-03-22</td>\n",
       "      <td>Large</td>\n",
       "      <td>FastAPI, KDB+, TensorFlow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>King Inc</td>\n",
       "      <td>Tech</td>\n",
       "      <td>Quant Researcher</td>\n",
       "      <td>MLflow, FastAPI, Azure, PyTorch, SQL, GCP</td>\n",
       "      <td>Entry</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>East Paige, CM</td>\n",
       "      <td>124496-217204</td>\n",
       "      <td>2025-09-18</td>\n",
       "      <td>Large</td>\n",
       "      <td>BigQuery, PyTorch, Scikit-learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Cooper, Archer and Lynch</td>\n",
       "      <td>Tech</td>\n",
       "      <td>AI Product Manager</td>\n",
       "      <td>Scikit-learn, C++, Pandas, LangChain, AWS, R</td>\n",
       "      <td>Mid</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Perezview, FI</td>\n",
       "      <td>50908-123743</td>\n",
       "      <td>2024-05-08</td>\n",
       "      <td>Large</td>\n",
       "      <td>TensorFlow, BigQuery, MLflow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Hall LLC</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Excel, Keras, SQL, Hugging Face</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Contract</td>\n",
       "      <td>North Desireeland, NE</td>\n",
       "      <td>98694-135413</td>\n",
       "      <td>2025-02-24</td>\n",
       "      <td>Large</td>\n",
       "      <td>PyTorch, LangChain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1996</td>\n",
       "      <td>Mueller, Ellis and Clark</td>\n",
       "      <td>Finance</td>\n",
       "      <td>NLP Engineer</td>\n",
       "      <td>Flask, FastAPI, Power BI</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Washingtonmouth, SD</td>\n",
       "      <td>90382-110126</td>\n",
       "      <td>2024-04-22</td>\n",
       "      <td>Large</td>\n",
       "      <td>MLflow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1997</td>\n",
       "      <td>Roberts-Yu</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>AI Product Manager</td>\n",
       "      <td>R, Flask, Excel, C++, CUDA, Scikit-learn</td>\n",
       "      <td>Mid</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Joshuafort, ZA</td>\n",
       "      <td>47848-137195</td>\n",
       "      <td>2023-12-02</td>\n",
       "      <td>Large</td>\n",
       "      <td>KDB+, LangChain, MLflow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1998</td>\n",
       "      <td>Brooks, Williams and Randolph</td>\n",
       "      <td>Education</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Hugging Face, Excel, Scikit-learn, R, MLflow</td>\n",
       "      <td>Entry</td>\n",
       "      <td>Contract</td>\n",
       "      <td>West Brittanyburgh, CG</td>\n",
       "      <td>134994-180108</td>\n",
       "      <td>2023-10-29</td>\n",
       "      <td>Large</td>\n",
       "      <td>PyTorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1999</td>\n",
       "      <td>Castaneda-Smith</td>\n",
       "      <td>Education</td>\n",
       "      <td>Quant Researcher</td>\n",
       "      <td>AWS, Python, Scikit-learn</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Contract</td>\n",
       "      <td>Anthonyshire, OM</td>\n",
       "      <td>62388-82539</td>\n",
       "      <td>2024-08-10</td>\n",
       "      <td>Large</td>\n",
       "      <td>MLflow, TensorFlow, FastAPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2000</td>\n",
       "      <td>Estes Group</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Quant Researcher</td>\n",
       "      <td>Flask, TensorFlow, Power BI</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Benjaminview, NE</td>\n",
       "      <td>55835-97374</td>\n",
       "      <td>2025-02-20</td>\n",
       "      <td>Startup</td>\n",
       "      <td>MLflow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      job_id                   company_name    industry  \\\n",
       "0          1                Foster and Sons  Healthcare   \n",
       "1          2        Boyd, Myers and Ramirez        Tech   \n",
       "2          3                       King Inc        Tech   \n",
       "3          4       Cooper, Archer and Lynch        Tech   \n",
       "4          5                       Hall LLC     Finance   \n",
       "...      ...                            ...         ...   \n",
       "1995    1996       Mueller, Ellis and Clark     Finance   \n",
       "1996    1997                     Roberts-Yu  Automotive   \n",
       "1997    1998  Brooks, Williams and Randolph   Education   \n",
       "1998    1999                Castaneda-Smith   Education   \n",
       "1999    2000                    Estes Group     Finance   \n",
       "\n",
       "                     job_title  \\\n",
       "0                 Data Analyst   \n",
       "1     Computer Vision Engineer   \n",
       "2             Quant Researcher   \n",
       "3           AI Product Manager   \n",
       "4               Data Scientist   \n",
       "...                        ...   \n",
       "1995              NLP Engineer   \n",
       "1996        AI Product Manager   \n",
       "1997              Data Analyst   \n",
       "1998          Quant Researcher   \n",
       "1999          Quant Researcher   \n",
       "\n",
       "                                        skills_required experience_level  \\\n",
       "0     NumPy, Reinforcement Learning, PyTorch, Scikit...              Mid   \n",
       "1                       Scikit-learn, CUDA, SQL, Pandas           Senior   \n",
       "2             MLflow, FastAPI, Azure, PyTorch, SQL, GCP            Entry   \n",
       "3          Scikit-learn, C++, Pandas, LangChain, AWS, R              Mid   \n",
       "4                       Excel, Keras, SQL, Hugging Face           Senior   \n",
       "...                                                 ...              ...   \n",
       "1995                           Flask, FastAPI, Power BI           Senior   \n",
       "1996           R, Flask, Excel, C++, CUDA, Scikit-learn              Mid   \n",
       "1997       Hugging Face, Excel, Scikit-learn, R, MLflow            Entry   \n",
       "1998                          AWS, Python, Scikit-learn           Senior   \n",
       "1999                        Flask, TensorFlow, Power BI           Senior   \n",
       "\n",
       "     employment_type                location salary_range_usd posted_date  \\\n",
       "0          Full-time           Tracybury, AR     92860-109598  2025-08-20   \n",
       "1          Full-time          Lake Scott, CU     78523-144875  2024-03-22   \n",
       "2          Full-time          East Paige, CM    124496-217204  2025-09-18   \n",
       "3          Full-time           Perezview, FI     50908-123743  2024-05-08   \n",
       "4           Contract   North Desireeland, NE     98694-135413  2025-02-24   \n",
       "...              ...                     ...              ...         ...   \n",
       "1995      Internship     Washingtonmouth, SD     90382-110126  2024-04-22   \n",
       "1996          Remote          Joshuafort, ZA     47848-137195  2023-12-02   \n",
       "1997        Contract  West Brittanyburgh, CG    134994-180108  2023-10-29   \n",
       "1998        Contract        Anthonyshire, OM      62388-82539  2024-08-10   \n",
       "1999       Full-time        Benjaminview, NE      55835-97374  2025-02-20   \n",
       "\n",
       "     company_size                  tools_preferred  \n",
       "0           Large                  KDB+, LangChain  \n",
       "1           Large        FastAPI, KDB+, TensorFlow  \n",
       "2           Large  BigQuery, PyTorch, Scikit-learn  \n",
       "3           Large     TensorFlow, BigQuery, MLflow  \n",
       "4           Large               PyTorch, LangChain  \n",
       "...           ...                              ...  \n",
       "1995        Large                           MLflow  \n",
       "1996        Large          KDB+, LangChain, MLflow  \n",
       "1997        Large                          PyTorch  \n",
       "1998        Large      MLflow, TensorFlow, FastAPI  \n",
       "1999      Startup                           MLflow  \n",
       "\n",
       "[2000 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "url = r'/users/yaswanthkumarvejandla/Downloads/AI ML Engineer/projects/ml_project/ai_job_market.csv'\n",
    "df = pd.read_csv(url)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e158f31-b97a-444f-bfcf-6c9fec49e972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            job_id\n",
      "count  2000.000000\n",
      "mean   1000.500000\n",
      "std     577.494589\n",
      "min       1.000000\n",
      "25%     500.750000\n",
      "50%    1000.500000\n",
      "75%    1500.250000\n",
      "max    2000.000000\n"
     ]
    }
   ],
   "source": [
    "# Display dataset info\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b971a402-a2ce-4eff-9361-3f8fb42fa31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values:\n",
      " job_id              0\n",
      "company_name        0\n",
      "industry            0\n",
      "job_title           0\n",
      "skills_required     0\n",
      "experience_level    0\n",
      "employment_type     0\n",
      "location            0\n",
      "salary_range_usd    0\n",
      "posted_date         0\n",
      "company_size        0\n",
      "tools_preferred     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Missing Values Check\n",
    "print(\"\\nMissing Values:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b728f93-1d40-4369-9699-b1692f9a134b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ AI-Generated Insights:\n",
      " The tools in the dataset are listed in the `tools_preferred` column. Here is a summary of the tools:\n",
      "\n",
      "1. **KDB+**: Preferred by 7 companies (including Foster and Sons, Roberts-Yu, Castaneda-Smith)\n",
      "2. **LangChain**: Preferred by 6 companies (including Foster and Sons, Cooper, Archer and Lynch, Estes Group)\n",
      "3. **FastAPI**: Preferred by 5 companies (including Boyd, Myers and Ramirez, King Inc, Mueller, Ellis and Clark)\n",
      "4. **TensorFlow**: Preferred by 5 companies (including King Inc, Estes Group, Castaneda-Smith, Benjaminview, North Desireeland)\n",
      "5. **PyTorch**: Preferred by 4 companies (including King Inc, Cooper, Archer and Lynch, Mueller, Ellis and Clark)\n",
      "6. **Scikit-learn**: Preferred by 3 companies (including Foster and Sons, Brooks, Williams and Randolph)\n",
      "7. **MLflow**: Preferred by 3 companies (including Foster and Sons, Roberts-Yu, Estes Group)\n",
      "8. **BigQuery**: Preferred by 2 companies (including King Inc, Castaneda-Smith)\n",
      "9. **AWS**: Preferred by 2 companies (including Cooper, Archer and Lynch, Brooks, Williams and Randolph)\n",
      "10. **R**: Preferred by 1 company (Joshuafort)\n",
      "11. **Excel**: Preferred by 1 company (Hall LLC)\n",
      "12. **Hugging Face**: Preferred by 1 company (Hall LLC)\n",
      "13. **C++**: Preferred by 1 company (Boyd, Myers and Ramirez)\n",
      "14. **SQL**: Preferred by multiple companies\n",
      "15. **Pandas**: Preferred by multiple companies\n",
      "16. **NumPy**: Preferred by one company (Foster and Sons)\n",
      "17. **Reinforcement Learning**: Preferred by one company (Foster and Sons)\n",
      "18. **CUDA**: Preferred by two companies (Boyd, Myers and Ramirez, Hall LLC)\n",
      "19. **Power BI**: Preferred by two companies (King Inc, Estes Group)\n",
      "\n",
      "Note that some companies prefer multiple tools, but I've only listed each tool once in the above summary.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "def generate_insights(df_summary):\n",
    "    prompt = f\"give me the tools in the data set :\\n\\n{df_summary}\"\n",
    "    response = ollama.chat(model=\"llama3.2\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "    return response['message']['content']\n",
    "\n",
    "# Generate AI Insights\n",
    "summary = df\n",
    "insights = generate_insights(summary)\n",
    "print(\"\\nðŸ”¹ AI-Generated Insights:\\n\", insights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e820ef12-aecb-4e1c-b3a6-dc964bfa4d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ AI-Generated Insights:\n",
      " This is a Pandas DataFrame in Python that contains data about various jobs and their requirements. Here's an explanation of the different columns:\n",
      "\n",
      "1. **job_id**: A unique identifier for each job.\n",
      "2. **company_name** and **industry**: The name of the company offering the job and its industry, respectively.\n",
      "3. **job_title**: The title of the job being applied for.\n",
      "4. **skills_required**: A comma-separated list of skills required to perform the job.\n",
      "5. **experience_level**: The level of experience required for the job, which can be:\n",
      "\t* Entry: 0-2 years\n",
      "\t* Mid: 3-6 years\n",
      "\t* Senior: 7+ years\n",
      "6. **employment_type**: The type of employment offered, which can be:\n",
      "\t* Full-time\n",
      "\t* Contract\n",
      "\t* Internship\n",
      "\t* Remote\n",
      "7. **location**: The location where the job is being offered.\n",
      "8. **salary_range_usd**: A range of salaries for the position in USD.\n",
      "9. **posted_date**: The date when the job was posted.\n",
      "10. **company_size**: The size of the company offering the job, which can be:\n",
      "\t* Small\n",
      "\t* Medium\n",
      "\t* Large\n",
      "\t* Startup\n",
      "11. **tools_preferred**: A list of tools preferred by the company for a particular position.\n",
      "\n",
      "Some observations about this data:\n",
      "\n",
      "* There are 2000 rows in the DataFrame, each representing a different job.\n",
      "* The data is mostly focused on jobs in tech industries (Healthcare, Tech, Finance).\n",
      "* Many companies have large teams and offer full-time employment with competitive salaries.\n",
      "* Some positions require high-level skills like AI, Machine Learning, or Data Science.\n",
      "* There are also some entry-level and contract positions available.\n",
      "\n",
      "Some possible ways to analyze this data:\n",
      "\n",
      "1. **Job title analysis**: You can analyze the distribution of job titles and see which ones are most common.\n",
      "2. **Skills required analysis**: You can analyze the skills required for each position and identify areas where there is a high demand.\n",
      "3. **Salary range analysis**: You can analyze the salary ranges offered by companies to understand market trends.\n",
      "4. **Company size analysis**: You can analyze the distribution of company sizes and see which ones are most common.\n",
      "\n",
      "Some possible code examples:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Load the data into a DataFrame\n",
      "df = pd.read_csv('job_data.csv')\n",
      "\n",
      "# Analyze job titles\n",
      "print(df['job_title'].value_counts())\n",
      "\n",
      "# Analyze skills required\n",
      "print(df['skills_required'].str.split(',').explode().value_counts())\n",
      "\n",
      "# Analyze salary ranges\n",
      "print(df['salary_range_usd'].str.split('-').map(lambda x: int(x[0]) + int(x[1])).value_counts())\n",
      "\n",
      "# Analyze company size\n",
      "print(df['company_size'].value_counts())\n",
      "```\n",
      "\n",
      "Note that these are just examples, and you may want to customize the analysis based on your specific needs.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "def generate_insights(dataset, user_prompt):\n",
    "    # Use the user prompt dynamically\n",
    "    prompt = f\"{user_prompt}\\n\\n{dataset}\"\n",
    "    response = ollama.chat(\n",
    "        model=\"llama3.2\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response['message']['content']\n",
    "\n",
    "# Example usage\n",
    "dataset = df  # Your dataset summary or data\n",
    "\n",
    "# Ask the user for their own prompt each time\n",
    "user_prompt = input(\"Enter your prompt for the dataset: \")\n",
    "\n",
    "insights = generate_insights(dataset, user_prompt)\n",
    "print(\"\\nðŸ”¹ AI-Generated Insights:\\n\", insights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5ed5138-8578-4356-9c81-533920aa556a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "IMPORTANT: You are using gradio version 3.41.2, however version 4.44.1 is available, please upgrade.\n",
      "--------\n",
      "Running on public URL: https://ba5865e0fd8fdd9155.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://ba5865e0fd8fdd9155.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def eda_analysis(file, user_prompt):\n",
    "    df = pd.read_csv(file.name)\n",
    "    dataset = df  # or just df if you want full data\n",
    "    insights = generate_insights(dataset, user_prompt)\n",
    "    return insights\n",
    "\n",
    "# Create Web Interface with prompt input\n",
    "demo = gr.Interface(\n",
    "    fn=eda_analysis,\n",
    "    inputs=[\n",
    "        gr.File(label=\"Upload CSV File\"),\n",
    "        gr.Textbox(label=\"Enter your custom prompt\", placeholder=\"e.g. Give me the tools in the dataset\")\n",
    "    ],\n",
    "    outputs=\"text\",\n",
    "    title=\"ðŸ§  AI-Powered EDA with LLaMA\",\n",
    "    description=\"Upload a CSV file and enter your own prompt to get AI-generated insights.\"\n",
    ")\n",
    "# Launch App\n",
    "demo.launch(share=True)  # Use share=True for Google Colab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3315f27f-6d18-45f2-880b-70fc0f712047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69b4465-4362-42df-a878-7a00e6220fce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
